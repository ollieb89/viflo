---
phase: 13-agent-architecture
plan: "01"
type: execute
wave: 1
depends_on: []
files_modified:
  - .agent/skills/agent-architecture/SKILL.md
autonomous: true
requirements: [AGENT-01, AGENT-02, AGENT-03, AGENT-04, AGENT-05]

must_haves:
  truths:
    - "Developer can follow the Quick Start and have a tool-using Claude agent running via Anthropic SDK in under 15 minutes"
    - "Every agent code example includes hard MAX_TURNS and MAX_TOKENS_PER_RUN constants — no example ships without guardrails"
    - "Developer can follow the streaming section and understand how to wire SSE from FastAPI StreamingResponse to a Next.js client via Vercel AI SDK v6"
    - "Developer can read the LangGraph section and understand stateful multi-agent graphs with the LangGraph 1.x stability note"
    - "Developer can read episodic memory via pgvector with a cross-reference to the RAG skill and a 1-paragraph MCP overview"
    - "The Gotchas section names at least 3 pitfalls with warning signs, why-it-happens, anti-pattern code, and fix code"
    - "A 'When NOT to use agents' callout is visually distinct and appears before or at the top of Gotchas"
  artifacts:
    - path: ".agent/skills/agent-architecture/SKILL.md"
      provides: "Complete agent-architecture skill at auth-systems depth"
      min_lines: 380
      contains: "MAX_TURNS"
    - path: ".agent/skills/agent-architecture/SKILL.md"
      provides: "Guardrail constants present in every tool-use example"
      contains: "MAX_TOKENS_PER_RUN"
    - path: ".agent/skills/agent-architecture/SKILL.md"
      provides: "LangGraph multi-agent section"
      contains: "LangGraph 1.x"
    - path: ".agent/skills/agent-architecture/SKILL.md"
      provides: "Streaming section with correct stack"
      contains: "StreamingResponse"
    - path: ".agent/skills/agent-architecture/SKILL.md"
      provides: "MCP overview paragraph"
      contains: "Model Context Protocol"
  key_links:
    - from: ".agent/skills/agent-architecture/SKILL.md"
      to: ".agent/skills/rag-vector-search/SKILL.md"
      via: "episodic memory cross-reference"
      pattern: "rag-vector-search"
    - from: ".agent/skills/agent-architecture/SKILL.md"
      to: "references/multi-agent-patterns.md"
      via: "See references link"
      pattern: "references/multi-agent-patterns"
    - from: ".agent/skills/agent-architecture/SKILL.md"
      to: "references/memory-orchestration.md"
      via: "See references link"
      pattern: "references/memory-orchestration"
---

<objective>
Rewrite `.agent/skills/agent-architecture/SKILL.md` from 80 lines to auth-systems depth (~400 lines), covering tool-using agents with mandatory guardrails, SSE streaming (FastAPI → Next.js), LangGraph stateful multi-agent graphs, episodic memory via pgvector, MCP overview, and a When-NOT-to-use callout + 3 named Gotchas with anti-pattern/fix code pairs.

Purpose: Deliver AGENT-01 through AGENT-05. The current SKILL.md is a thin shell pointing to references/ files. This plan promotes production-essential patterns into the main body, following the same depth standard achieved in Phase 12 for the RAG skill.

Output: `.agent/skills/agent-architecture/SKILL.md` (~400 lines, ≤500 lines per INFRA-02)
</objective>

<execution_context>
@/home/ollie/.claude/get-shit-done/workflows/execute-plan.md
@/home/ollie/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/13-agent-architecture/13-CONTEXT.md
@.planning/phases/13-agent-architecture/13-RESEARCH.md
@.planning/phases/12-rag-vector-search/12-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Rewrite SKILL.md to auth-systems depth</name>
  <files>.agent/skills/agent-architecture/SKILL.md</files>
  <action>
Rewrite `.agent/skills/agent-architecture/SKILL.md` completely. The current file is 80 lines; the target is ~400 lines at auth-systems depth (≤500 per INFRA-02). Follow the RAG skill structure (Phase 12) as the depth template.

**Locked decisions from CONTEXT.md (non-negotiable):**
- Quick Start Step 1: working agent with NO tools (simplest state, < 5 min). Step 2: add tool (`fetch_url` / web search) with `MAX_TURNS` guardrail wired in.
- `MAX_TURNS` and `MAX_TOKENS_PER_RUN` as named constants in EVERY tool-use code example from the first tool example onward — no example ships without them.
- Python and TypeScript side-by-side throughout (tab-switcher or paired fenced blocks, both complete and equivalent).
- Gotchas: all 3 required pitfalls with warning signs + why-it-happens + anti-pattern code + fix code. Tone: "Don't do this" framing.
- When NOT to use agents: visually distinct callout (markdown blockquote `>` or `> **Note**`) before or at the top of Gotchas.
- Streaming: FastAPI `StreamingResponse` (Python) → Next.js client via Vercel AI SDK v6 `useChat`. This stack is locked.

**Required document structure (sections in this order):**

```
---
name: agent-architecture
description: [update to reflect new depth]
---

# Agent Architecture

> See `references/multi-agent-patterns.md` for LangGraph orchestrator implementation details.
> See `references/memory-orchestration.md` for episodic memory, context management, and state persistence.

## Quick Start

Step 1: Running agent, no tools (Python + TypeScript). Uses `client.messages.create()` with `max_tokens=1024`. No guardrails needed — no loop.

Step 2: Tool-using agent with `MAX_TURNS` and `MAX_TOKENS_PER_RUN`. Use `fetch_url` tool (fetches a URL, returns first 2000 chars). Manual tool-use loop: check `stop_reason == "tool_use"`, execute tool, append `tool_result`, loop. Both Python and TypeScript complete and equivalent.

After Step 2 code blocks: mention `client.beta.messages.tool_runner()` (TS) / `client.beta.messages.tool_runner()` (Py) as the shortcut callout — but note the manual loop is preferable for teaching because guardrail placement is explicit.

## 1. Guardrails (required, not optional)

Explain why `MAX_TURNS` and `MAX_TOKENS_PER_RUN` are non-negotiable. Reference cost runaway as the failure mode. Show the constants table:

| Constant | Recommended default | Effect |
|---|---|---|
| MAX_TURNS | 10 | Aborts loop after N iterations |
| MAX_TOKENS_PER_RUN | 4096 | Caps output tokens per call |

Note: `max_tokens` must be set explicitly on every `messages.create()` call — default varies by SDK version.

## 2. Streaming (FastAPI → Next.js)

Explain when streaming matters (long-running agents, UX responsiveness).

Server (Python FastAPI): async generator yielding SSE-formatted chunks. `StreamingResponse(generator, media_type="text/event-stream")`. Use `client.messages.stream()` context manager. Yield `f"data: {json.dumps({'text': text})}\n\n"` per chunk. End with `"data: [DONE]\n\n"`.

Client (Next.js + Vercel AI SDK v6): Show the Next.js API route approach using `streamText` + `@ai-sdk/anthropic` `createAnthropic()` + `convertToModelMessages` + `toUIMessageStreamResponse()`. Then show the React component using `useChat` from `@ai-sdk/react` with `parts` API (render `part.type === 'text'`).

Note that `TextStreamChatTransport` can point at a custom URL (like the FastAPI endpoint) but the FastAPI endpoint must produce AI SDK-compatible SSE format, not raw Anthropic SSE — recommend the Next.js API route proxy pattern for simplicity.

## 3. Multi-Agent with LangGraph

Open with: "LangGraph 1.x (stable since October 2025, zero breaking changes) — use `create_react_agent` from `langgraph.prebuilt`."

Show Python `create_react_agent` example with `InMemorySaver` (dev) and note for production: use `PostgresSaver` from `langgraph-checkpoint-postgres`. Include `recursion_limit: MAX_TURNS` in the config dict — this is the LangGraph equivalent of the manual loop guard.

Note TypeScript SDK exists (`@langchain/langgraph`) but is not covered here — Python is the primary LangGraph ecosystem.

Decision matrix (can be the existing one or updated version):

| Situation | Pattern |
|---|---|
| Task fits in one context window | Single agent + tools |
| Requires parallelism | Orchestrator + parallel subagents |
| Exceeds context window | Orchestrator + sequential subagents |
| Long-running with human checkpoints | LangGraph with PostgresSaver |

## 4. Memory and MCP

**Episodic memory via pgvector:** 8-10 lines. Show `store_episode()` and `recall_episodes()` functions (Python) using `pgvector.encode()`. Require `embedding_model_version` column — same pattern as `document_chunks` in the RAG skill. Cross-reference: "See the RAG skill (`rag-vector-search`) for full HNSW index setup, chunking strategies, and eval patterns."

**MCP overview (1 paragraph):** Use the verbatim MCP paragraph from RESEARCH.md: "MCP (Model Context Protocol) is an open standard introduced by Anthropic in November 2024, now governed by the Linux Foundation / AAIF..." through "...MCP is the integration layer to reach for."

## When NOT to Use Agents

Visually distinct callout (blockquote). Brief criteria (not a full decision tree):
- Single deterministic transformation → no agent needed
- Task has a known, fixed set of steps → workflow or function is faster and cheaper
- Latency is the primary constraint → agent loop adds 300–2000ms per turn
- Accuracy must be >99% → agent error rates compound (see Bag-of-Agents pitfall below)

## Gotchas

**Pitfall 1: Runaway Costs (Agent Loop Without Termination)**
- Warning signs (3 bullet points from RESEARCH.md)
- Why it happens: tested with small prompts that terminate in 1–2 turns
- Anti-pattern (Python `while True` loop with no guard)
- Fix (Python `for turn in range(MAX_TURNS)` with named constants and `raise RuntimeError`)

**Pitfall 2: Untyped Sub-Agent Handoffs**
- Warning signs (3 bullet points from RESEARCH.md)
- Why it happens: multi-agent prototyped with string handoffs because it's easy
- Anti-pattern (TypeScript: `const result = await orchestratorAgent(task)` passed as raw string)
- Fix (TypeScript: `interface SearchHandoff`, `validateHandoff()` with zod or manual validation)

**Pitfall 3: Bag-of-Agents Error Multiplication**
- Warning signs (3 bullet points from RESEARCH.md)
- Why it happens: developers treat agent accuracy as additive; it's multiplicative (0.9^5 = 59%)
- Anti-pattern (Python: 5 agents in sequence, no validation)
- Fix (Python: validate at each stage with typed schema; abort early if confidence drops)
- Rule of thumb callout: "If a single capable model can do the task, use one agent."

## Version Context

| Library | Version | Notes |
|---|---|---|
| @anthropic-ai/sdk | 0.37.x | TypeScript — tool_use stop reason pattern |
| anthropic | 0.40.x | Python equivalent |
| ai (Vercel AI SDK) | 6.x (6.0.97) | useChat, streamText, convertToModelMessages |
| @ai-sdk/anthropic | latest | createAnthropic() — breaking change from new Anthropic() |
| @ai-sdk/react | 6.x | useChat hook |
| langgraph | 1.x | Stable since October 2025, zero breaking changes |
| langgraph-checkpoint-postgres | 1.x | PostgresSaver for production |
| fastapi | 0.115+ | StreamingResponse + async generator for SSE |
```

**Style rules (from CONTEXT.md and Phase 12 precedent):**
- Python and TypeScript code blocks appear side-by-side (or labeled `# Python` / `// TypeScript` within the same section)
- Gotcha code blocks: anti-pattern block has `# BAD:` comment first line; fix block has `# GOOD:` or `// GOOD:` comment
- No horizontal rules between every section — use `##` headings to separate
- Keep total line count ≤500 (INFRA-02). Target ~400-430.
  </action>
  <verify>
    <automated>
      wc -l /home/ollie/Development/Tools/viflo/.agent/skills/agent-architecture/SKILL.md | awk '{if ($1 >= 380 && $1 <= 500) print "PASS: " $1 " lines"; else print "FAIL: " $1 " lines (expected 380–500)"}'
      grep -c "MAX_TURNS" /home/ollie/Development/Tools/viflo/.agent/skills/agent-architecture/SKILL.md
      grep -c "MAX_TOKENS_PER_RUN" /home/ollie/Development/Tools/viflo/.agent/skills/agent-architecture/SKILL.md
      grep -c "StreamingResponse" /home/ollie/Development/Tools/viflo/.agent/skills/agent-architecture/SKILL.md
      grep -c "LangGraph 1" /home/ollie/Development/Tools/viflo/.agent/skills/agent-architecture/SKILL.md
      grep -c "Model Context Protocol" /home/ollie/Development/Tools/viflo/.agent/skills/agent-architecture/SKILL.md
      grep -c "rag-vector-search" /home/ollie/Development/Tools/viflo/.agent/skills/agent-architecture/SKILL.md
      grep -c "Runaway\|runaway" /home/ollie/Development/Tools/viflo/.agent/skills/agent-architecture/SKILL.md
      grep -c "Untyped\|untyped" /home/ollie/Development/Tools/viflo/.agent/skills/agent-architecture/SKILL.md
      grep -c "Bag-of-Agents\|bag-of-agents" /home/ollie/Development/Tools/viflo/.agent/skills/agent-architecture/SKILL.md
    </automated>
    <manual>Verify the Quick Start section reads coherently for a developer starting from scratch. Confirm Python and TypeScript are both complete in Step 2. Confirm MAX_TURNS appears in every tool-use loop example.</manual>
  </verify>
  <done>
    SKILL.md is 380–500 lines. MAX_TURNS appears ≥3 times (Step 2 example + at least 2 other tool-use examples). MAX_TOKENS_PER_RUN appears ≥2 times. StreamingResponse appears ≥1 time. "LangGraph 1" appears ≥1 time. "Model Context Protocol" appears ≥1 time. "rag-vector-search" cross-reference appears ≥1 time. All 3 Gotcha pitfall names present.
  </done>
</task>

</tasks>

<verification>
Run the automated checks from the verify block. All 9 grep counts must be ≥1. Line count must be 380–500.

```bash
cd /home/ollie/Development/Tools/viflo
wc -l .agent/skills/agent-architecture/SKILL.md
grep -c "MAX_TURNS" .agent/skills/agent-architecture/SKILL.md
grep -c "MAX_TOKENS_PER_RUN" .agent/skills/agent-architecture/SKILL.md
grep -c "StreamingResponse" .agent/skills/agent-architecture/SKILL.md
grep -c "LangGraph 1" .agent/skills/agent-architecture/SKILL.md
grep -c "Model Context Protocol" .agent/skills/agent-architecture/SKILL.md
grep -c "rag-vector-search" .agent/skills/agent-architecture/SKILL.md
grep -c "Runaway\|runaway" .agent/skills/agent-architecture/SKILL.md
grep -c "Untyped\|untyped" .agent/skills/agent-architecture/SKILL.md
grep -c "Bag-of-Agents\|bag-of-agents" .agent/skills/agent-architecture/SKILL.md
```
</verification>

<success_criteria>
- SKILL.md is 380–500 lines
- Every tool-use loop example contains MAX_TURNS and MAX_TOKENS_PER_RUN as named constants
- Quick Start: Step 1 (no tools) + Step 2 (fetch_url tool with guardrails) both complete in Python and TypeScript
- Streaming section covers FastAPI SSE server + Next.js AI SDK v6 client (locked stack)
- LangGraph section references v1.x stability, create_react_agent, PostgresSaver vs InMemorySaver
- Episodic memory cross-references the RAG skill with rag-vector-search path
- MCP covered in 1 paragraph
- All 3 Gotchas present with warning signs, why-it-happens, anti-pattern code, fix code
- "When NOT to use agents" callout is visually distinct (blockquote)
- Total line count ≤500 (INFRA-02 compliance)
</success_criteria>

<output>
After completion, create `.planning/phases/13-agent-architecture/13-01-SUMMARY.md` following the summary template at `/home/ollie/.claude/get-shit-done/templates/summary.md`.

Include:
- Line count of the final SKILL.md
- Grep counts for all 9 verification checks
- Any deviations from the plan and how they were handled
- Requirements addressed: AGENT-01, AGENT-02, AGENT-03, AGENT-04, AGENT-05
</output>
