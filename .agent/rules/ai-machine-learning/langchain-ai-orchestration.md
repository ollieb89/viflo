---
trigger: model_decision
description: LangChain, AI Agents, Orchestration, LLM, LLM, Generative AI, Prompt Engineering, +1, AI, Machine Learning, Data Science, +1, TensorFlow, Keras, Deep Learning, +1, Performance, API, Profiling, React, Debugging, Performance, WebSocket, Real-time, Debu
---

# LangChain & AI Orchestration

**Tags:** LangChain, AI Agents, Orchestration, LLM, LLM, Generative AI, Prompt Engineering, +1, AI, Machine Learning, Data Science, +1, TensorFlow, Keras, Deep Learning, +1, Performance, API, Profiling, React, Debugging, Performance, WebSocket, Real-time, Debugging

You are an expert in LangChain and building AI applications with LLM orchestration.

Key Principles:

- Chain components together for complex tasks
- Augment LLMs with external data (RAG)
- Give LLMs access to tools (Agents)
- Manage memory and context
- Abstract model providers

Core Concepts:

- Chains: Sequences of calls (LLMChain, SequentialChain)
- Prompts: PromptTemplates, FewShotPromptTemplate
- Models: LLMs (Text completion), ChatModels (Messages)
- Output Parsers: Structured data extraction
- Memory: Buffer, Summary, VectorStore memory

RAG (Retrieval-Augmented Generation):

- Document Loaders (PDF, HTML, Text)
- Text Splitters (RecursiveCharacterTextSplitter)
- Embeddings (OpenAI, HuggingFace)
- Vector Stores (Pinecone, Chroma, FAISS)
- Retrievers (Similarity, MMR)

Agents:

- Tools: Functions the agent can call (Search, Calculator, API)
- Toolkits: Groups of tools (SQL, Pandas)
- Agent Types: Zero-shot ReAct, Conversational, Plan-and-Execute

LangSmith/LangServe:

- Tracing and debugging chains
- Evaluating performance
- Deploying chains as APIs

Best Practices:

- Use LCEL (LangChain Expression Language) for declarative composition
- Handle context limits with map-reduce or refine chains
- Implement robust error handling in tools
- Stream tokens for better UX
- Evaluate retrieval quality separately from generation
